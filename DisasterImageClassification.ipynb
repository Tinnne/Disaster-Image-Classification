{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0e7c72",
   "metadata": {},
   "source": [
    "# Disaster Image Classification\n",
    "\n",
    "Made By:\n",
    "- Austin Kane - 27022229232\n",
    "- Andreas Immanuel Lukito - 2702211595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab04e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\Anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0, EfficientNetB2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d81d830",
   "metadata": {},
   "source": [
    "## Set the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c7b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224) # MobileNetV2's input size is 224x224 \n",
    "BATCH_SIZE = 32 \n",
    "NUM_CLASSES = 11\n",
    "DATA_DIR = 'Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8252b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize the images\n",
    "    validation_split=0.2, # Train Val Split\n",
    "    \n",
    "    # Image Augmentation\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee52680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10943 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE, # Scale the image to fit model's input\n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4221da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2731 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE, # Scale the image to fit model's input\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e285e34",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d87ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(*IMAGE_SIZE, 3)\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3bd606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "MobileNet = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1650ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_metric = F1Score(num_classes=NUM_CLASSES, average='macro')\n",
    "MobileNet.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[f1_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cfbe3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7130b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "342/342 [==============================] - 138s 398ms/step - loss: 0.7384 - f1_score: 0.5933 - val_loss: 0.4350 - val_f1_score: 0.7470\n",
      "Epoch 2/10\n",
      "342/342 [==============================] - 129s 379ms/step - loss: 0.5068 - f1_score: 0.7181 - val_loss: 0.4048 - val_f1_score: 0.7444\n",
      "Epoch 3/10\n",
      "342/342 [==============================] - 130s 379ms/step - loss: 0.4497 - f1_score: 0.7517 - val_loss: 0.3695 - val_f1_score: 0.7768\n",
      "Epoch 4/10\n",
      "342/342 [==============================] - 129s 377ms/step - loss: 0.4363 - f1_score: 0.7644 - val_loss: 0.3603 - val_f1_score: 0.7664\n",
      "Epoch 5/10\n",
      "342/342 [==============================] - 132s 385ms/step - loss: 0.4209 - f1_score: 0.7647 - val_loss: 0.3627 - val_f1_score: 0.7869\n",
      "Epoch 6/10\n",
      "342/342 [==============================] - 130s 380ms/step - loss: 0.3929 - f1_score: 0.7864 - val_loss: 0.3409 - val_f1_score: 0.7991\n",
      "Epoch 7/10\n",
      "342/342 [==============================] - 129s 378ms/step - loss: 0.3861 - f1_score: 0.7858 - val_loss: 0.3367 - val_f1_score: 0.7997\n",
      "Epoch 8/10\n",
      "342/342 [==============================] - 128s 375ms/step - loss: 0.3967 - f1_score: 0.7791 - val_loss: 0.3554 - val_f1_score: 0.7852\n",
      "Epoch 9/10\n",
      "342/342 [==============================] - 129s 379ms/step - loss: 0.3828 - f1_score: 0.7869 - val_loss: 0.3522 - val_f1_score: 0.7740\n",
      "Epoch 10/10\n",
      "342/342 [==============================] - 129s 376ms/step - loss: 0.3760 - f1_score: 0.7970 - val_loss: 0.3347 - val_f1_score: 0.7900\n"
     ]
    }
   ],
   "source": [
    "history = MobileNet.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f4ca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 26s 300ms/step - loss: 0.3294 - f1_score: 0.7978\n",
      "Validation F1-Score: 0.7978\n"
     ]
    }
   ],
   "source": [
    "loss, f1 = MobileNet.evaluate(val_generator)\n",
    "print(f\"Validation F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb9f931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 28s 312ms/step\n",
      "Accuracy:  0.8942\n",
      "Precision: 0.8467\n",
      "Recall:    0.7966\n",
      "F1 Score:  0.8163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "y_pred_probs = MobileNet.predict(val_generator)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_true = val_generator.classes\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02909af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Damaged_infrastructure, Damaged_water, Fire_Urban, and Land_Slide\n",
      "Precision: 0.7592\n",
      "Recall:    0.6751\n",
      "F1 Score:  0.7011\n"
     ]
    }
   ],
   "source": [
    "label_map = val_generator.class_indices\n",
    "\n",
    "class_names_to_include = [\"Damaged_infrastructure\", \"Damaged_water\", \"Fire_Urban\", \"Land_Slide\"]\n",
    "class_indices_to_include = [label_map[name] for name in class_names_to_include]\n",
    "\n",
    "precision = precision_score(y_true, y_pred, labels=class_indices_to_include, average='macro')\n",
    "recall = recall_score(y_true, y_pred, labels=class_indices_to_include, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, labels=class_indices_to_include, average='macro')\n",
    "\n",
    "print(\"Evaluation for Damaged_infrastructure, Damaged_water, Fire_Urban, and Land_Slide\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fcd202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
